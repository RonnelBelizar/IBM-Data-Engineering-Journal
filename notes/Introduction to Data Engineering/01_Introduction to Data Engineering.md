# Topic: Module 1 - Introduction to Data Engineering

## 📝 Key Concepts

Data Engineering Ecosystem:

    1. Data Warehouse Engineers:
        - Develop and optimizes data system
    2. Data Scientists:
        - Designs and analyzes systems to predict patterns from previous set of data.
    3. Data Managers:
        - Oversees systems to ensure compliance and system integrity.
    4. BI (Business Intelligence) Analysts:
        - Understands the actual data for utilization for business growth.
    5. Data Analysts:
        - Utilizes raw data to convert it into a readable data.

What is Data Engineering?
    
    Collecting Source Data -> Processing -> Storing -> Making data accessible

        - Provides robust and scaleable structure
        - Includes tools and technologies for data manipulation
        - Involves understanding the complexities of data and how it is leveraged for fact finding and decision making

    The goal of Data Engineering is to make quality data available for analytics and decision-making. And it does this by collecting raw source data, processing data so it becomes usable, storing data, and making quality data available to users securely.  

Responsibilities of a Data Engineer:

    Data-Analytics is ready when

        - Accurate
        - Reliable
        - Complies to regulations
        - Accessible to consumers when they need it

        1. Extract, organize, and integrate data  for disparrte sources
        2. Prepare data for analysis and reporting by transforming and cleansing it
        3. Design and manage data pipelines from source to destination systems
        4. Setup and manage the infrastructure

    Technical Skills:

        Operating Systems

        Infrastructure Components

            - Virtual machines
            - Networking
            - Application Services
                - Load Balancing
            - Cloud-based Services
                - Amazon, Google, IBM, Microsoft

        Databases and Data Warehouses:

            1. RDBMS (Relational Database Management System)

                - It is software that lets you store, organize, and manage data in a relational (table-based) structure.

                    Patients table:

                    Patient_ID |    Name      |     DOB
                        101    | Maria Santos | 1990-03-12
                
                - IBM DB2
                - MySQL
                - Oracle Databse
                - PostgreSQL

            2. NoSQL (Not Only SQL)

                It is a type of database that does not rely on the strict table/row/column structure of relational databases. Instead, it is designed for:
                    - Flexibility with unstructured or semi-structured data
                    - High scalability (handling millions of users, big data, real-time apps)
                    - Faster reads/writes in some use cases

                1. Redis
                2. MongoDB
                3. Cassandra
                4. Neo4J

            3. Data Warehouses

                A data warehouse is a centralized storage system designed specifically for analytics and reporting.

                Think of it like the “single source of truth” for an organization’s data — all the cleaned, structured data from different systems (RDBMS, NoSQL, CSVs, APIs, EHRs, etc.) gets funneled in, so analysts and data scientists can query it easily.

                1. Oracle Exadata
                2. IBM DB2 Warehouse on Cloud
                3. IBM Netezza Performance Server
                4. Amazon Redshift

        Data Pipelines:

            1. Apache Beam
                - Pipeline coding framework
            2. Airflow
                - Pipeline scheduling and orchestration
            3. Dataflow
                - Cloud service that runs Beam pipelines

        ETL Tools:

            1. IBM Infosphere
            2. AWS Glue
            3. improvado

        Languages:

            1. Query Languages
                - SQL
                - SQL-like query language for NoSQL

            2. Programming Languages
                - Python
                - R
                - Java

            3. Shell and Scripting Languages

                - A shell is a program that lets you interact with your computer’s operating system by typing commands (instead of clicking icons).

                - Example: Bash (Linux/Mac), PowerShell (Windows)

                - You use it to navigate files, run programs, manage processes, connect to servers, etc.

                    - Unix/Linux Shell
                    - Powershell

        Big Data Processing Tools

            1. hadoop
            2. HIVE
            3. Apache Spark

    Functional Skills:

        -   Intersection of software engineering and data science     

            - Convert business requirements into technical specifications
            - Work with comomplete software development lifecycle

                Ideation -> Architecture -> Design -> Prototyping -> Testing -> Deployment

            - Understand data's potential application in business
            - Understand risks of poor data management

## 🔑 Important Terms
- Term 1 → your definition
- Term 2 → your definition

## 📊 Examples
```python
# Example code snippet
```

## 💡 My Understanding

    - Each role in the Data Engineering ecosystem has their own work to solidify a system manipulating data from data gathering down to data accessibility for end users for the betterment of a business. Theere are variety of technical skkills a Data Engineer could acquire over time and specialize on it depending on the business requirements. This field is abundant on studies and technical advancements which requires an individual like me aspiring to transition to stay curious and remain very interested to develop.

---
